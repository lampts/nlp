{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING:theano.configdefaults:g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import numpy as np  \n",
    "from gensim.models import LdaModel\n",
    "import os\n",
    "import codecs\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:test\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.debug(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:loading Dictionary object from /home/laampt/nlp/releases/docsent_695Kdoc.dict\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary.load(\"/home/laampt/nlp/releases/docsent_695Kdoc.dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:loading LdaModel object from /home/laampt/nlp/releases/docsent_695Kdoc_lda_bow_200topics_auto_50iterations_4workers_1passes_50iter_l1tok_r131\n",
      "INFO:gensim.utils:loading id2word recursively from /home/laampt/nlp/releases/docsent_695Kdoc_lda_bow_200topics_auto_50iterations_4workers_1passes_50iter_l1tok_r131.id2word.* with mmap=None\n",
      "INFO:gensim.utils:loading expElogbeta from /home/laampt/nlp/releases/docsent_695Kdoc_lda_bow_200topics_auto_50iterations_4workers_1passes_50iter_l1tok_r131.expElogbeta.npy with mmap=None\n",
      "INFO:gensim.utils:setting ignored attribute state to None\n",
      "INFO:gensim.utils:setting ignored attribute dispatcher to None\n",
      "INFO:gensim.utils:loading LdaModel object from /home/laampt/nlp/releases/docsent_695Kdoc_lda_bow_200topics_auto_50iterations_4workers_1passes_50iter_l1tok_r131.state\n",
      "INFO:gensim.utils:loading sstats from /home/laampt/nlp/releases/docsent_695Kdoc_lda_bow_200topics_auto_50iterations_4workers_1passes_50iter_l1tok_r131.state.sstats.npy with mmap=None\n"
     ]
    }
   ],
   "source": [
    "lda = LdaModel.load('/home/laampt/nlp/releases/docsent_695Kdoc_lda_bow_200topics_auto_50iterations_4workers_1passes_50iter_l1tok_r131')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(936365 unique tokens: [u'Kennycao', u'Shigaraki-ky\\u014d', u'cmays', u'spiders', u'Nampo']...)\n",
      "LdaModel(num_terms=936365, num_topics=200, decay=0.5, chunksize=2000)\n"
     ]
    }
   ],
   "source": [
    "print dictionary\n",
    "print lda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr2 = joblib.load(\"/home/laampt/nlp/docsent/model/lda_lr_10Ktrain_cv10_200topics_r202.pkl\")\n",
    "svc2 = joblib.load(\"/home/laampt/nlp/docsent/model/lda_svc_10Ktrain_cv10_200topics_r202.pkl\")\n",
    "gbc2 = joblib.load(\"/home/laampt/nlp/docsent/model/lda_gbc_10Ktrain_cv10_200topics_r202.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,./:;<=>?@[\\]^`{|}~\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "import string\n",
    "import unicodedata\n",
    "import sys\n",
    "import codecs\n",
    "\n",
    "STOPWORDS = [u\"wwDATEww\", u\"wwTIMEww\", u\"wwEMAILww\", u\"wwIPww\", u\"wwURLww\", u\"wwNUMBERww\"]\n",
    "with codecs.open(\"/home/laampt/orm/10K/5K/lda/stopwords.txt\", encoding='utf-8', mode='r') as fin:\n",
    "        STOPWORDS += fin.readlines()\n",
    "        \n",
    "tbl = dict.fromkeys(i for i in xrange(sys.maxunicode)\n",
    "                      if unicodedata.category(unichr(i)).startswith('P') and i != 45 and i!= 95)\n",
    "\n",
    "def vi_trans_unicode(su):\n",
    "    return su.translate(tbl)\n",
    "\n",
    "vpunctuation = string.punctuation.replace('-','').replace('_','')\n",
    "print vpunctuation\n",
    "\n",
    "def vi_strip_text(s):\n",
    "    s = re.sub(r\"&amp;\", \"\", s)\n",
    "    s = re.sub(u\"\\u2026\", \"\", s, re.UNICODE) # ...\n",
    "    s = re.sub(u\"\\u2014\", \"\", s, re.UNICODE) # emdash\n",
    "    s = re.sub(u\"\\u201d\", \"\", s, re.UNICODE) #\n",
    "    s = re.sub(u\"\\u201c\", \"\", s, re.UNICODE) #\n",
    "    s = re.sub(r\"<([^>]+)>\", \"\", s)\n",
    "    s = re.sub(r\"(\\s|\\\\n|\\\\r|\\\\t)+\", \" \", s)\n",
    "    s = re.sub(\"([%s]+)\" % vpunctuation, \" \", s)\n",
    "    s = ' '.join([w if not w[0].isdigit() else u\"_NUM\" for w in s.strip().split()])\n",
    "    return s\n",
    "\n",
    "def vi_strip_text2(s):\n",
    "    s = re.sub(r\"&amp;\", \"\", s)\n",
    "    s = vi_trans_unicode(s)\n",
    "    s = re.sub(r\"<([^>]+)>\", \"\", s)\n",
    "    s = re.sub(r\"(\\s|\\\\n|\\\\r|\\\\t)+\", \" \", s)\n",
    "    s = re.sub(r\"__+\", \"_\", s)\n",
    "    s = re.sub(r\"--+\", \"-\", s)\n",
    "    s = ' '.join([w if not w[0].isdigit() else u\"_NUM\" for w in s.strip().split()])\n",
    "    return s\n",
    "\n",
    "def vi_clean(line):\n",
    "    words = line.replace('.',' ').strip().split()\n",
    "    words = [w for w in words if not(u\"_NUM\" in w) and not(w.startswith(u'-'))]\n",
    "    return ' '.join(words)\n",
    "\n",
    "def vi_clean2(line):\n",
    "    words = line.replace('.',' ').strip().split()\n",
    "    words = [w for w in words if not (w in STOPWORDS) and not(u\"_NUM\" in w) and not(w.startswith(u'-'))]\n",
    "    return ' '.join(words)\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "url_post = \"http://vlsp.vietlp.org:8080/demo/?page=seg_pos_chunk\"\n",
    "header_post = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/4\",\n",
    "    \"Content-Type\": \"application/x-www-form-urlencoded; charset=UTF-8\"\n",
    "}\n",
    "\n",
    "url_post_l1 = \"http://192.168.0.125:8080/api/v1.0/document/filter?level=1\"\n",
    "\n",
    "def tokenize_soup(soup):\n",
    "    try:\n",
    "        sentences = soup.findAll('div', {'class': \"sentence\"})\n",
    "        toks = [ s.find('tr').findAll('td')[1:] for s in sentences]\n",
    "        toks = [t.contents[0] for tok in toks for t in tok]\n",
    "        return ' '.join(toks)\n",
    "    except Exception, e:\n",
    "        print e\n",
    "        \n",
    "def get_tokens(INPUT):\n",
    "    try:\n",
    "        payload = {r\"input\":INPUT}\n",
    "        rsp = requests.post(url_post, data=payload, headers=header_post)\n",
    "        soup = BeautifulSoup(rsp.content)\n",
    "        return tokenize_soup(soup)\n",
    "    except Exception, e:\n",
    "        print e\n",
    "        \n",
    "def get_tokens2(INPUT):\n",
    "    try:\n",
    "        rsp = requests.post(url_post_l1, data=INPUT)\n",
    "        results = json.loads(rsp.content)\n",
    "        return results[\"document\"]\n",
    "    except Exception, e:\n",
    "        print e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nguỵ_biện nói cho cùng là vấn_đề chân_lí và sự_thật.\n"
     ]
    }
   ],
   "source": [
    "print get_tokens2(\"Nguỵ biện nói cho cùng là vấn đề chân lí và sự thật.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize(doc, dictionary, lda):\n",
    "    try:\n",
    "        bow = dictionary.doc2bow(doc.split())\n",
    "        tm = lda[bow]\n",
    "        vec = tuple_to_vect(tm)\n",
    "        return vec\n",
    "    except Exception, e:\n",
    "        print e\n",
    "    \n",
    "def voting_vec4(test_vec, cls):\n",
    "    names = [type(clf).__name__ for clf in cls]\n",
    "    scores = [clf.predict(test_vec) for clf in cls]\n",
    "    return zip(names,scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tuple_to_vect(tup, dim=200):\n",
    "    vec = [0]*dim\n",
    "    for k,v in tup:\n",
    "        vec[k] = v\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LogisticRegression', array([ 1.])),\n",
       " ('LinearSVC', array([ 1.])),\n",
       " ('GradientBoostingClassifier', array([ 1.]))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT = u\"\"\"Nguỵ biện nói cho cùng là vấn đề chân lí và sự thật. Vấn đề ở VN là chân lí nó được bóp méo và vặn vẹo làm cho người dân nghĩ rằng chỉ có một chân lí duy nhất. Quan sát trên báo chí, internet, đến nghị trường, từ những người có học (cỡ sư sĩ), đến chính khách, và cả thường dân ai ai cũng dùng những lí lẽ mà họ không biết là lỗi nguỵ biện. Chẳng hạn như gần đây nhất có người cảnh báo rằng coi chừng lợi dụng dân chủ, nhưng trong thực tế đó cũng là một dạng của nguỵ biện – nguỵ biện dựa vào nguồn tin vu vơ. Còn sự thật thì cũng bị giả tạo và giả dối sản sinh (như vụ Lê Văn Tám). Những thói nguỵ biện nó được xây dựng trên sự dối trá đã được tạo ra quá lâu, nên khó có thể chỉnh sửa một sớm một chiều. Chỉ khi nào nền giáo dục có sự tham gia bình đẳng từ các nhóm xã hội, thay vì bị sự kiểm soát của một thế lực chính trị, thì tình trạng nguỵ biện vẫn còn.\"\"\"\n",
    "test_vec = vectorize(INPUT, dictionary, lda)\n",
    "voting_vec4(test_vec, [lr2,svc2,gbc2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LogisticRegression', array([ 0.])),\n",
       " ('LinearSVC', array([ 1.])),\n",
       " ('GradientBoostingClassifier', array([ 1.]))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT = u\"\"\"Trong đoàn có lãnh_đạo các Bộ_An_ninh Quốc_gia Bộ_Nội_vụ cơ_quan_An_ninh Cảnh_sát các_nước Trung_Quốc Nga Cuba các_nước ASEAN lãnh_đạo tổ_chức Aseanpol và Interpol. Thay_mặt Chính_phủ Thủ_tướng_Nguyễn_Tấn_Dũng hoan_nghênh và đánh_giá_cao các đoàn_đại_biểu quốc_tế sang dự Lễ_kỷ_niệm wwNUMBERww năm Ngày truyền_thống CAND Việt_Nam và wwNUMBERww năm Ngày hội toàn_dân_bảo_vệ_an_ninh_Tổ_quốc. Sự có_mặt của các đại_biểu quốc_tế đã mang đến cho Việt_Nam nói_chung và cho lực_lượng CAND Việt_Nam nói_riêng sự gắn_bó tình_cảm hữu_nghị sự_hợp_tác tốt_đẹp. Thủ_tướng_Nguyễn_Tấn_Dũng bày_tỏ vui_mừng trước những bước phát_triển mạnh_mẽ trong quan_hệ_hợp_tác nhiều mặt giữa Việt_Nam với các_nước trong ASEAN Trung_Quốc Nga Cuba các tổ_chức_quốc_tế cũng như sự_hợp_tác hiệu_quả giữa Bộ_Công_an Việt_Nam với các lực_lượng_an_ninh cảnh_sát nội_vụ tình_báo của các_nước và_các tổ_chức Aseanpol Interpol.\"\"\"\n",
    "test_vec = vectorize(INPUT, dictionary, lda)\n",
    "voting_vec4(test_vec, [lr2,svc2,gbc2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LogisticRegression', array([ 0.])),\n",
       " ('LinearSVC', array([ 0.])),\n",
       " ('GradientBoostingClassifier', array([ 0.]))]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT = u\"\"\"Tuần_trước ở Montreal tôi đã không_chơi tốt nhưng tôi luôn nỗ_lực. Tôi đã có_một kết_quả tích_cực trước Chardy. Vượt qua một đối_thủ như cậu_ấy là tin tốt_lành với tôi. Trận_đấu tiếp_theo sẽ còn rất khó_khăn.\"\"\"\n",
    "test_vec = vectorize(INPUT, dictionary, lda)\n",
    "voting_vec4(test_vec, [lr2,svc2,gbc2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LogisticRegression', array([ 1.])),\n",
       " ('LinearSVC', array([ 0.])),\n",
       " ('GradientBoostingClassifier', array([ 0.]))]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT = u\"\"\"\"\"\"\n",
    "test_vec = vectorize(INPUT, dictionary, lda)\n",
    "voting_vec4(test_vec, [lr2,svc2,gbc2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4.69 times longer than the fastest. This could mean that an intermediate result is being cached \n",
      "1000 loops, best of 3: 648 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit lda[dictionary.doc2bow(u\"Tuần_trước ở Montreal tôi đã không_chơi tốt nhưng tôi luôn nỗ_lực. Tôi đã có_một kết_quả tích_cực trước Chardy. Vượt qua một đối_thủ như cậu_ấy là tin tốt_lành với tôi. Trận_đấu tiếp_theo sẽ còn rất khó_khăn.\".split())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4.08 times longer than the fastest. This could mean that an intermediate result is being cached \n",
      "10000 loops, best of 3: 30.1 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit lr2.predict(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 loops, best of 3: 51.9 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit gbc2.predict(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 9.89 times longer than the fastest. This could mean that an intermediate result is being cached \n",
      "10000 loops, best of 3: 30.2 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit svc2.predict(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
