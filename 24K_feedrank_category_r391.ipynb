{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feedrank and category on Viettel subjects\n",
    "=====================\n",
    "\n",
    "To rank a feed is fact or not?\n",
    "\n",
    "* Unsupervised to cluster on Kmean based\n",
    "* Categorized based on auto label from unsuperived clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re \n",
    "import string\n",
    "import unicodedata\n",
    "import sys\n",
    "\n",
    "STOPWORDS = [u\"ấy\", u\"bị\", u\"bởi\", u\"cả\", u\"các\", u\"cái\", u\"cần\", u\"càng\", u\"chỉ\", u\"chiếc\", u\"cho\", u\"chứ\", u\"chưa\", \n",
    "             u\"chuyện\", u\"có\", u\"có_thể\", u\"cứ\", u\"của\", u\"cùng\", u\"cũng\", u\"đã\", u\"đang\", u\"đây\", u\"để\", u\"đến_nỗi\", \n",
    "             u\"đều\", u\"điều\", u\"do\", u\"đó\", u\"được\", u\"dưới\", u\"gì\", u\"khi\", u\"không\", u\"là\", u\"lại\", u\"lên\", u\"lúc\", \n",
    "             u\"mà\", u\"mỗi\", u\"một cách\", u\"này\", u\"nên\", u\"nếu\", u\"ngay\", u\"nhiều\", u\"như\", u\"nhưng\", u\"những\", u\"nơi\", \n",
    "             u\"nữa\", u\"phải\", u\"qua\", u\"ra\", u\"rằng\", u\"rất\", u\"rồi\", u\"sau\", u\"sẽ\", u\"so\", u\"sự\", u\"tại\", u\"theo\", \n",
    "             u\"thì\", u\"trên\", u\"trước\", u\"từ\", u\"từng\", u\"và\", u\"vẫn\", u\"vào\", u\"vậy\", u\"vì\", u\"việc\", u\"với\", u\"vừa\",\n",
    "             u\"_num\", u\"wwdateww\", u\"wwtimeww\", u\"wwemailww\", u\"wwipww\", u\"wwurlww\", u\"wwnumberww\"\n",
    "            ]\n",
    "\n",
    "tbl = dict.fromkeys(i for i in xrange(sys.maxunicode)\n",
    "                      if unicodedata.category(unichr(i)).startswith('P') and i != 45 and i!= 95)\n",
    "\n",
    "def vi_trans_unicode(su):\n",
    "    return su.translate(tbl)\n",
    "\n",
    "def vi_strip_text2(s):\n",
    "    s = re.sub(r\"&amp;\", \"\", s)\n",
    "    s = vi_trans_unicode(s)\n",
    "    s = re.sub(r\"<([^>]+)>\", \"\", s)\n",
    "    s = re.sub(r\"(\\s|\\\\n|\\\\r|\\\\t)+\", \" \", s)\n",
    "    s = re.sub(r\"__+\", \"_\", s)\n",
    "    s = re.sub(r\"--+\", \"-\", s)\n",
    "    s = re.sub(r'(.)\\1+', r'\\1\\1', s)\n",
    "    s = ' '.join([w if not w[0].isdigit() else u\"wwNUMBERww\" for w in s.strip().split()])\n",
    "    return s\n",
    "\n",
    "\n",
    "def vi_clean3(line):\n",
    "    words = line.replace('.','').strip().split()\n",
    "    words = [w.lower() for w in words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "def vi_remove_stop_1char(line):\n",
    "    words = line.split()\n",
    "    words = [w for w in words if w not in STOPWORDS and len(w) > 1]\n",
    "    return ' '.join(words)\n",
    "\n",
    "import requests\n",
    "import codecs\n",
    "import json\n",
    "\n",
    "tok_url = \"http://192.168.0.215:8081/api/v1.0/document/filter\"\n",
    "\n",
    "def get_tokens(tok_url, data):\n",
    "    try:\n",
    "        rq = requests.post(tok_url, data=data.encode('utf-8'))\n",
    "        if rq.content:\n",
    "            tok_doc = ' '.join(json.loads(rq.content)['sentences'])\n",
    "        else:\n",
    "            tok_doc = None\n",
    "        return tok_doc\n",
    "    except Exception, e:\n",
    "        print e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer_tfidf = joblib.load(\"/home/laampt/nlp/feedrank/model/feedrank_24Kdoc_vectorizer_tfidf.pkl\")\n",
    "mbk20 = joblib.load(\"/home/laampt/nlp/feedrank/model/feedrank_24Kdoc_mbk20.pkl\")\n",
    "mbk50 = joblib.load(\"/home/laampt/nlp/feedrank/model/feedrank_24Kdoc_mbk50.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error=u'strict',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=0.95, max_features=None, min_df=2,\n",
      "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words=None, strip_accents=None, sublinear_tf=True,\n",
      "        token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "print vectorizer_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniBatchKMeans(batch_size=2000, compute_labels=True, init='k-means++',\n",
      "        init_size=None, max_iter=100, max_no_improvement=100,\n",
      "        n_clusters=20, n_init=10, random_state=None,\n",
      "        reassignment_ratio=0.01, tol=0.0, verbose=0)\n",
      "MiniBatchKMeans(batch_size=2000, compute_labels=True, init='k-means++',\n",
      "        init_size=None, max_iter=100, max_no_improvement=100,\n",
      "        n_clusters=50, n_init=10, random_state=None,\n",
      "        reassignment_ratio=0.01, tol=0.0, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "print mbk20\n",
    "print mbk50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mbk_prediction(feed, vectorizer_tfidf, mbk2, mbk50):\n",
    "    \"\"\"\n",
    "    Input: given raw feed, vectorizer, kmean 20 clusters, kmean 50 clusters\n",
    "    Output: 1 if feed is user opinion alike else 0\n",
    "    \"\"\"\n",
    "    s_test_clean = vi_remove_stop_1char(vi_clean3(vi_strip_text2(feed)))\n",
    "    vecs = vectorizer_tfidf.transform([s_test_clean])\n",
    "    p20 = mbk2.predict(vecs)[0]\n",
    "    p50 = mbk50.predict(vecs)[0]\n",
    "    \n",
    "    if (p20 == 10 and p50 == 35) or (p20 == 11 and p50 == 31) or (p20 == 12 and p50 == 32) or (p20 == 16 and p50 == 9):\n",
    "        prediction = 1\n",
    "    else:\n",
    "        prediction = 0\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "feed = u\"minh gooner chuyển xài viettel gói_cước đi thấy xài good nhá\"\n",
    "print mbk_prediction(feed, vectorizer_tfidf, mbk20, mbk50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_tfidf10 = joblib.load(\"/home/laampt/nlp/feedrank/estimator/39/lr_tfidf_99auc_10cv2.pkl\")\n",
    "svc_tfidf10 = joblib.load(\"/home/laampt/nlp/feedrank/estimator/39/svc_tfidf_99auc_10cv2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0)\n",
      "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n"
     ]
    }
   ],
   "source": [
    "print lr_tfidf10\n",
    "print svc_tfidf10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mega_prediction(feed, vectorizer_tfidf, lr_tfidf10, svc_tfidf10, w=0.6):\n",
    "    \"\"\"\n",
    "    Input: given raw feed, vectorizer, lr, svm classifier\n",
    "    Output: 1 if feed is user opinion alike else 0\n",
    "    \"\"\"\n",
    "    s_test_clean = vi_remove_stop_1char(vi_clean3(vi_strip_text2(feed)))\n",
    "    vec = vectorizer_tfidf.transform([s_test_clean]).toarray()[0,:].T\n",
    "    prediction = lr_tfidf10.predict(vec) * w + svc_tfidf10.predict(vec) * (1-w)\n",
    "    prediction = 1 if (prediction[0] > 0.5) else 0\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "feed = u\"minh gooner chuyển xài viettel gói_cước đi thấy xài good nhá\"\n",
    "print mega_prediction(feed, vectorizer_tfidf, lr_tfidf10, svc_tfidf10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORT\n",
      "--------------------------------------------------------------------------------\n",
      "POS: \n",
      "viettel làm_việc chuyên_nghiệp và mình tới đây lần nào cũng hài_lòng\n",
      "PREDICT: MBK [0] MEGA [0]\n",
      "................................................................................\n",
      "NEG: \n",
      "chương_trình khuyến_mãi thẻ_cào nhân dịp quốc_khánh wwDATEww Nạp wwNUMBERww được wwNUMBERww ông chú vt bảo vậy\n",
      "PREDICT: MBK [0] MEGA [0]\n",
      "................................................................................\n"
     ]
    }
   ],
   "source": [
    "pos1 = u\"viettel làm_việc chuyên_nghiệp và mình tới đây lần nào cũng hài_lòng\"\n",
    "neg2 = u\"chương_trình khuyến_mãi thẻ_cào nhân dịp quốc_khánh wwDATEww Nạp wwNUMBERww được wwNUMBERww ông chú vt bảo vậy\"\n",
    "\n",
    "pred_mbk_pos1 = mbk_prediction(pos1, vectorizer_tfidf, mbk20, mbk50)\n",
    "pred_mbk_neg2 = mbk_prediction(neg2, vectorizer_tfidf, mbk20, mbk50)\n",
    "\n",
    "pred_mega2_pos1 = mega_prediction(pos1, vectorizer_tfidf, lr_tfidf10, svc_tfidf10)\n",
    "pred_mega2_neg2 = mega_prediction(neg2, vectorizer_tfidf, lr_tfidf10, svc_tfidf10)\n",
    "\n",
    "print \"REPORT\"\n",
    "print \"-\" * 80\n",
    "\n",
    "print \"POS: \"\n",
    "print pos1\n",
    "print \"PREDICT: MBK [{}] MEGA [{}]\".format(pred_mbk_pos1, pred_mega2_pos1)\n",
    "print \".\" * 80\n",
    "\n",
    "print \"NEG: \"\n",
    "print neg2\n",
    "print \"PREDICT: MBK [{}] MEGA [{}]\".format(pred_mbk_neg2, pred_mega2_neg2)\n",
    "print \".\" * 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tôi yêu viettel làm_việc ngon_lành luôn nhiệt tình_nguyện hết_mình\n",
      "PREDICT: MBK 0  MEGA 1\n"
     ]
    }
   ],
   "source": [
    "inp = u\"tôi yêu viettel làm việc ngon lành luôn nhiệt tình nguyện hết mình\"\n",
    "feed = get_tokens(tok_url, inp)\n",
    "print feed\n",
    "print \"PREDICT: MBK {}  MEGA {}\".format(mbk_prediction(feed, vectorizer_tfidf, mbk20, mbk50), mega_prediction(feed, vectorizer_tfidf, lr_tfidf10, svc_tfidf10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 1.8 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit mbk_prediction(feed, vectorizer_tfidf, mbk20, mbk50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4.63 times longer than the fastest. This could mean that an intermediate result is being cached \n",
      "1000 loops, best of 3: 837 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit mega_prediction(feed, vectorizer_tfidf, lr_tfidf10, svc_tfidf10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 64.14 MiB, increment: 0.18 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit mbk_prediction(feed, vectorizer_tfidf, mbk20, mbk50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 64.18 MiB, increment: 0.04 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit mega_prediction(feed, vectorizer_tfidf, lr_tfidf10, svc_tfidf10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
